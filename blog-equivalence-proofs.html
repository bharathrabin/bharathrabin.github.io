<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<title>Equivalence Proofs</title>
	<link href="https://fonts.googleapis.com/css?family=Inconsolata" rel="stylesheet">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="styles/reset.css">
	<link rel="stylesheet" href="styles/-debug.css">
	<link rel="stylesheet" href="styles/article.css">
	<link rel="stylesheet" href="styles/article-image.css">

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
		<article>
		<h1>Equivalence Proofs For Turing Machines</h1>
		<time datetime="05-30-2021">May 30, 2021</time>
		<p>In this post I would like to go over equivalence proofs for Turing machines. I have already mentioned in my previous post on <a href="turingmachines.html">Turing machines</a>, that the nitty gritty specifics that define a Turing machine are entirely arbitrary. Instead of defining a Turing machine \(M\) over an alphabet set \(\Gamma\), we could define a Turing machine \(M'\) over the alphabet set \(\Gamma' = \{0, 1, st, bl\}\). Both these Turing machines are equivalent and can compute the same class of functions. The proof relies on the fact that to represent an element \(\gamma \in \Gamma\) we require at most \(O(lg|\Gamma|)\) bits. The equivalence mentioned above is formally stated in the following claim</p> 
		<div class="gray-box">
			<p class="p-inside-def">
				<strong>Claim:</strong> For every function \(f: \{0, 1\}^{*} \mapsto \{0, 1\}\) and time-constructable \(T: \mathbb{N} \mapsto \mathbb{N}\), if \(f\) is computable in time \(T(n)\) by a Turing machine \(M\) using symbol set \(\Gamma\), then it is computable in time \(4lg|\Gamma|T(n)\) by a Turing machine \(M'\) using the symbol set \(\Gamma'=\{0, 1, st, bl\}\)
			</p>
			<p class="p-inside-def" id="p-before-list">
				<strong>Proof:</strong> The machine \(M'\) and \(M\) have equal number of tapes. Thus there exists a 1 to 1 correspondence between tapes of \(M\) and tapes of \(M'\). Since any symbol \(\gamma \in \Gamma\) can be encoded using atmost \(O(lg|\Gamma|)\) bits, one tape cell in any tape of \(M\) corresponds to at most \(O(lg|\Gamma|)\) cells in the corresponding tape of \(M'\). To simulate one computational step of \(M\) using \(M'\), the following steps are performed
			</p>
			<ul class="list-no-box">
				<li class="list-item"><p>Use \(lg|\Gamma|\) steps to read from each of the tapes, the \(lg|\Gamma|\) bits representing a symbol \(\gamma \in \Gamma\) that \(M\) currently reads as input.</p></li>
				<li class="list-item"><p> Use \(M'\)s state register to store the symbol read during the simulation of \(M\).</p></li>
				<li class="list-item"><p>Use \(M\)'s transition function to compute the symbols that \(M\) writes to its work tapes and in addition compute the new internal state of \(M\).</p></li>
				<li class="list-item"><p>\(M'\) uses atmost \(O(lg|\Gamma|)\) steps to simulate the writing of encodings for each of the symbols \(M\) writes to its work tapes.</p></li>
			</ul>
			<p class="p-inside-def"> To perform all of the above steps 
			\(M'\) needs access to the registers of \(M\) that store the internal state \(q \in Q\), the \(k\)-tuple that represents the symbols on the work tapes of \(M\) and a counter from 1 to \(k\). Therefore, the size of the internal register of \(M'\) is at most \(O(|Q||\Gamma|^{k}k)\)</p>
			<p class="p-inside-def"> Therefore, each of the bullet points above takes at most time \(O(lg|\Gamma|)\) albeit with the aid of a large internal register. Since there are four such steps the total time \(M'\) takes to complete the simulation of one step of \(M\) is \(4lg|\Gamma|\). Therefore if there are \(T(n)\) steps that \(M\) undertakes in total, then \(M'\) successfully simluates it in \(4lg|\Gamma|T(n)\)</p>
		</div>

		<p id="p-after-list">Another fascinating result that can be shown is that a Turing machine \(M\) with \(k\)-tapes and symbol set \(\Gamma\), is equivalent to a Turing machine \(M'\) with a single tape and symbol set \(\Gamma\). This informally can be thought off as more memory implies less computational time. We can show that we get a quadratic speed up by adding more tapes. Intuitively, this can be thought of as taking an \(n * n\) matrix and flattening it to get a length \(n^2\) vector. The proof  follows a very similar logic. Formally, it can be stated as follows</p>
		<div class="gray-box">
			<p class="p-inside-def">
				<strong>Claim:</strong> For every function \(f: \{0, 1\}^{*} \mapsto \{0, 1\}\) and time-constructable \(T: \mathbb{N} \mapsto \mathbb{N}\), if \(f\) is computable in time \(T(n)\) by a \(k\)-tape Turing machine \(M\) using symbol set \(\Gamma\), then it is computable in time \(O(kT(n)^2)\) by a single-tape Turing machine \(M'\) using the symbol set \(\Gamma\)
			</p>
			<p class="p-inside-def" id="p-before-list">
				<strong>Proof:</strong> The machine \(M'\) encodes the information from the \(k\)-tapes of \(M\) using a particular encoding scheme. The scheme is defined below
			</p>
			<ul class="list-no-box">
				<li class="list-item"><p>At positions \(1, k + 1, 2k + 1, ...\) we store the contents of tape-1 of \(M\)</p></li>
				<li class="list-item"><p>At positions \(2, k + 2, 2k + 2, ...\) we store the contents of tape-2 of \(M\)</p></li>
				<li class="list-item-special"><p> \(\vdots\)</p></li>
				<li class="list-item-special"><p> \(\vdots\)</p></li>
				<li class="list-item-special"><p> \(\vdots\)</p></li>
				<li class="list-item"><p>At position \(k, 2k, 3k, ...\) we store the contents of tape-k of \(M\)</p></li>
			</ul>
			<p>Thus we have successfully managed to squash the contents of a \(k\)-tape machine \(M\) onto a single-tape machine \(M'\). We have to keep track of \(k\)-tape heads of \(M\) as well, for every symbol \(\gamma \in \Gamma\), \(\hat{\gamma}\) denotes the symbol in \(M'\) if it is currently under a tape head in \(M\)</p>
			<p>To simulate a computational step of \(M\), \(M'\) performs two sweeps across its tape. The first sweep is from left to right, and during this sweep \(M'\) identifies the \(k\) symbols read by \(M\), i.e the symbols that are marked with \(\hat{}\)  . It then runs \(M\)'s transition function and sweeps back right to left to update the \(k\) symbols, the state and the \(k\)-tape heads of \(M\). It is easy to verify that \(M\) has the same output as \(M'\). For one computational step of \(M\) on input of size \(n\), \(M'\) does \(kT(n)\) steps. Therefore if \(M\) runs for \(T(n)\) steps then \(M'\) runs for \(O(kT(n)^2)\) steps.</p>
		</div>
		<p id="p-after-list">The above two claims are sometimes referred to as alphabet reduction and tape reduction. They are powerful ideas that show us that Turing machines are extremely robust models of computation and the problems that a Turing machine can solve do not depend on the nitty gritty specifics that define said machine.</p>
	</article>

</body>
</html>